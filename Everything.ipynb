{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "artificial-fleece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\GPU3\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from vit_keras import vit\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.backend import clear_session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "experienced-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\User\\Desktop\\Master_Y1\\Deep_learning\\BrainTumorDetection-main\\brain_tumor_dataset'\n",
    "classes = ['no', 'yes']\n",
    "def create_inception_v3():\n",
    "    base_incep = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "    x = base_incep.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(len(classes), activation='softmax')(x)\n",
    "    inception = Model(inputs=base_incep.input, outputs=predictions)\n",
    "    for layer in base_incep.layers:\n",
    "        layer.trainable = False\n",
    "    inception.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    return inception\n",
    "\n",
    "def create_resnet50():\n",
    "    base_resn = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "    x = base_resn.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(len(classes), activation='softmax')(x)\n",
    "    resnet = Model(inputs=base_resn.input, outputs=predictions)\n",
    "    for layer in base_resn.layers:\n",
    "        layer.trainable = False\n",
    "    resnet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    return resnet\n",
    "\n",
    "def create_vgg16():\n",
    "    base_model = keras.applications.VGG16(weights='imagenet', include_top=False) \n",
    "    base_model.trainable = False\n",
    "    inputs = keras.Input((224, 224, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = keras.layers.Dense(2, activation='sigmoid')(x)\n",
    "    VGG = keras.Model(inputs, outputs, name=\"VGG\")\n",
    "    VGG.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    return VGG\n",
    "\n",
    "def create_vit_b16():\n",
    "    b16 = vit.vit_b16(image_size=(img_size, img_size), activation='sigmoid', include_top=True, pretrained_top=False, classes=2)\n",
    "    b16.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    return b16\n",
    "\n",
    "def create_vit_b32():\n",
    "    b32 = vit.vit_b32(image_size=(img_size, img_size), activation='sigmoid', include_top=True, pretrained_top=False, classes=2)\n",
    "    b32.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    return b32\n",
    "\n",
    "def create_vit_l16():\n",
    "    l16 = vit.vit_l32(image_size=(224,224), activation='sigmoid', include_top=True, pretrained_top=False, classes=2)\n",
    "    l16.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    return l16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46dc9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(img_size):\n",
    "    data_path = r'C:\\Users\\User\\Desktop\\Master_Y1\\Deep_learning\\BrainTumorDetection-main\\brain_tumor_dataset'\n",
    "    classes = ['no', 'yes']\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for c in classes:\n",
    "        path = os.path.join(data_path, c)\n",
    "        class_num = classes.index(c)\n",
    "        for img in os.listdir(path):\n",
    "            img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
    "            img_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "            X.append(img_arr)\n",
    "            Y.append(class_num)\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    Y = to_categorical(Y, num_classes=len(classes))\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    return X, Y, kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13cdb933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(create_model_fn, X, Y, kf, batch_size=8, epochs=10):\n",
    "    val_accuracies = []\n",
    "    val_losses = []\n",
    "\n",
    "    best_history = None\n",
    "    best_val_accuracy = -np.inf\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "\n",
    "        clear_session()\n",
    "\n",
    "        # Create a new instance of the model with reset weights\n",
    "        model = create_model_fn()\n",
    "\n",
    "        model_history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, Y_val))\n",
    "\n",
    "        # Save the validation accuracy and validation loss for this fold\n",
    "        current_val_accuracy = model_history.history['val_binary_accuracy'][-1]\n",
    "        \n",
    "        val_accuracies.append(current_val_accuracy)\n",
    "        val_losses.append(model_history.history['val_loss'][-1])\n",
    "\n",
    "        # Check if the current fold has the highest validation accuracy\n",
    "        if current_val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = current_val_accuracy\n",
    "            best_history = model_history\n",
    "            \n",
    "        del model\n",
    "        del model_history\n",
    "        del X_train\n",
    "        del X_val\n",
    "        del Y_train\n",
    "        del Y_val\n",
    "        gc.collect()\n",
    "\n",
    "    # Calculate average validation accuracy and loss\n",
    "    avg_val_accuracy = np.mean(val_accuracies)\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "\n",
    "    return avg_val_accuracy, avg_val_loss, best_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42e416a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "X, Y, kf = load_and_preprocess_data(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e71598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 95ms/step - loss: 24.4662 - binary_accuracy: 0.6584 - val_loss: 9.0180 - val_binary_accuracy: 0.6275\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 6.6875 - binary_accuracy: 0.7525 - val_loss: 6.8528 - val_binary_accuracy: 0.7647\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 4.2047 - binary_accuracy: 0.7921 - val_loss: 8.0756 - val_binary_accuracy: 0.5490\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 2.7778 - binary_accuracy: 0.7624 - val_loss: 2.6543 - val_binary_accuracy: 0.8431\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.9209 - binary_accuracy: 0.7921 - val_loss: 2.0547 - val_binary_accuracy: 0.8039\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 94ms/step - loss: 12.2189 - binary_accuracy: 0.6931 - val_loss: 8.7054 - val_binary_accuracy: 0.7059\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 4.7087 - binary_accuracy: 0.7871 - val_loss: 2.8895 - val_binary_accuracy: 0.7255\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 2.5588 - binary_accuracy: 0.8267 - val_loss: 3.4574 - val_binary_accuracy: 0.7647\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 2.4417 - binary_accuracy: 0.8267 - val_loss: 3.3374 - val_binary_accuracy: 0.7647\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.6793 - binary_accuracy: 0.8663 - val_loss: 2.9174 - val_binary_accuracy: 0.7255\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 87ms/step - loss: 22.5363 - binary_accuracy: 0.6436 - val_loss: 4.3367 - val_binary_accuracy: 0.7843\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 3.6000 - binary_accuracy: 0.7871 - val_loss: 3.3661 - val_binary_accuracy: 0.7255\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 2.0624 - binary_accuracy: 0.8069 - val_loss: 2.7590 - val_binary_accuracy: 0.7059\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.1207 - binary_accuracy: 0.8564 - val_loss: 2.5764 - val_binary_accuracy: 0.6667\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.7109 - binary_accuracy: 0.8960 - val_loss: 2.8867 - val_binary_accuracy: 0.7255\n"
     ]
    }
   ],
   "source": [
    "avg_val_accuracy, avg_val_loss, inception_history = cross_validate(create_inception_v3, X, Y, kf, batch_size=8, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39178070",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"inception_history.pickle\"\n",
    "\n",
    "with open(file_path, 'wb') as file_pi:\n",
    "    pickle.dump(inception_history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c58535",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_val_accuracy, avg_val_loss, resnet_history = cross_validate(create_resnet50, X, Y, kf, batch_size=8, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c62fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"resnet_history.pickle\"\n",
    "\n",
    "with open(file_path, 'wb') as file_pi:\n",
    "    pickle.dump(resnet_history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_val_accuracy, avg_val_loss, vgg16_history = cross_validate(create_vgg16, X, Y, kf, batch_size=8, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"vgg16_history.pickle\"\n",
    "\n",
    "with open(file_path, 'wb') as file_pi:\n",
    "    pickle.dump(vgg16_history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cf25cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_val_accuracy, avg_val_loss, b16_history = cross_validate(create_vit_b16, X, Y, kf, batch_size=8, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c3baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"b16_history.pickle\"\n",
    "\n",
    "with open(file_path, 'wb') as file_pi:\n",
    "    pickle.dump(b16_history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa54f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_val_accuracy, avg_val_loss, b32_history = cross_validate(create_vit_b32, X, Y, kf, batch_size=8, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae56d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"b32_history.pickle\"\n",
    "\n",
    "with open(file_path, 'wb') as file_pi:\n",
    "    pickle.dump(b32_history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13871c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_val_accuracy, avg_val_loss, l16_history = cross_validate(create_vit_l16, X, Y, kf, batch_size=4, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bed310",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"l16_history.pickle\"\n",
    "\n",
    "with open(file_path, 'wb') as file_pi:\n",
    "    pickle.dump(l16_history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71dcf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_histories = {}\n",
    "model_names = ['b32', 'b16', 'vgg16', 'resnet', 'inception', 'l16']\n",
    "\n",
    "for model_name in model_names:\n",
    "    file_path = f\"{model_name}_history.pickle\"\n",
    "    with open(file_path, 'rb') as file_pi:\n",
    "        model_histories[model_name] = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d0fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bcbb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(history):\n",
    "\n",
    "    # Print the loss function\n",
    "    print(\"Loss function:\", history.history['loss'])\n",
    "\n",
    "    # Plot the training and validation loss\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Print the training and validation accuracy\n",
    "    train_acc = history.history['binary_accuracy']\n",
    "    val_acc = history.history['val_binary_accuracy']\n",
    "    print(\"Training Accuracy:\", train_acc)\n",
    "    print(\"Validation Accuracy:\", val_acc)\n",
    "\n",
    "#     # Plot the training and validation accuracy\n",
    "#     plt.plot(train_acc, label='Training Accuracy')\n",
    "#     plt.plot(val_acc, label='Validation Accuracy')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "#     # Calculate the confusion matrix for the validation set\n",
    "#     Y_pred = model.predict(X_val)\n",
    "#     Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "#     Y_val_classes = np.argmax(Y_val, axis=1)\n",
    "#     cm = confusion_matrix(Y_val_classes, Y_pred_classes)\n",
    "#     print(\"Confusion Matrix:\")\n",
    "#     print(cm)\n",
    "\n",
    "#     # Plot the confusion matrix\n",
    "#     sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "#     plt.show()\n",
    "\n",
    "    # Create a table showing the training and validation loss and accuracy\n",
    "    results_df = pd.DataFrame({'Loss': history.history['loss'], 'Accuracy': history.history['binary_accuracy'],\n",
    "                               'Val_Loss': history.history['val_loss'], 'Val_Accuracy': history.history['val_binary_accuracy']})\n",
    "    print(results_df)\n",
    "\n",
    "#     # Get the indices and confidence scores of the misclassified images\n",
    "#     misclassified_indices = np.where(Y_pred_classes != Y_val_classes)[0]\n",
    "#     misclassified_confidence = np.max(Y_pred[misclassified_indices], axis=1)\n",
    "\n",
    "#     # Plot the misclassified images with confidence scores\n",
    "#     plt.figure(figsize=(20, 20))\n",
    "#     for i, index in enumerate(misclassified_indices[:25]):\n",
    "#         plt.subplot(5, 5, i+1)\n",
    "#         plt.imshow(X_val[index])\n",
    "#         plt.axis('off')\n",
    "#         plt.title('Predicted: %s\\nActual: %s\\nConfidence: %.2f' % (Y_pred_classes[index], Y_val_classes[index], misclassified_confidence[i]))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044302f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(inception_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adf5da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
